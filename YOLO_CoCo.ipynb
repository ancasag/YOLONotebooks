{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLO_CoCo.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "kRtsp7-N5ZW_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Notebook 8: YOLO CoCo\n",
        "\n",
        "En este notebook vamos a ver como se entrena la red YOLO desde cero utilizando un dataset llamado CoCo. "
      ]
    },
    {
      "metadata": {
        "id": "O5cTunZG5ZW_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1- Recolección del dataset\n",
        "\n",
        "Para entrenar YOLO nos hace falta un conjunto de imágenes que formen el dataset. En este caso el dataset está formado por las imágenes de la base de datos de [CoCo](http://cocodataset.org/#home) desde 2015 hasta 2018. Este dataset fue diseñado con el fin de avanzar en la detección de objetos, segmentación, detección de puntos clave de personas, segmentación de elementos y generación de leyendas. Este paquete proporciona las API de Matlab, Python y Lua que ayudan a cargar, analizar y visualizar las anotaciones en CoCo. Este dataset cuenta con un total de 300.000 imágenes etiquetadas, que contienen objetos de 80 clases distintas (personas, gatos, barcos, trenes, perros, etc), divididas en estos grupos:\n",
        "\n",
        "<img src=\"imágenes/CoCoLista.png\" style=\"width:500px;\">\n",
        "\n",
        "En este caso nosotros sólo vamos a usar 122.260 imágenes de las 300.000 que hay en el dataset. Para obtener estos datos hay que ejecutar los siguientes comandos que descargan y descomprimen el dataset."
      ]
    },
    {
      "metadata": {
        "id": "3ODIoeDG5ZXA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!cp scripts/get_coco_dataset.sh data\n",
        "!cd data\n",
        "!bash get_coco_dataset.sh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DDCCSRbF5ZXC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ahora tendremos todos los datos y las etiquetas generados para usar en YOLO del 2014. Estas instrucciones nos habrán generado un directorio llamado coco donde se habrán descargado todas las imágenes del dataset. Interesa sobre todo remarcar que en ese directorio hay 2 carpetas de imágenes: train2014 y val 2014. Y además también hay una carpeta que contiene las imágenes anotadas de la manera que requiere YOLO. "
      ]
    },
    {
      "metadata": {
        "id": "Lu9RodDz5ZXD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2- Data augmentation\n",
        "En este caso al tener un dataset de 122.260 imágenes, no ha sido necesario aumentarlo aún más."
      ]
    },
    {
      "metadata": {
        "id": "CqId1QIY5ZXD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3- Anotación del dataset\n",
        "Ahora necesitamos que todas las imágenes están anotadas, es decir, YOLO necesita que cada imagen tenga un archivo .txt con una  línea por cada objeto que nos interese detectar. Aunque el formato de CoCo son archivos .json, este dataset también tiene una carpeta *labels* con las anotaciones de las imágenes en formato YOLO. Por lo que ya tenemos todas las anotaciones preparadas. "
      ]
    },
    {
      "metadata": {
        "id": "uQHwJyPk5ZXE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 4- Dataset split\n",
        "\n",
        "Este paso es un poco distinto a lo que se hace habitualmente. Normalmente se tiene un conjunto de imágenes y el usuario es el encargado de partirlas en dos conjuntos, uno de entrenamiento y otro de test, en este caso CoCo tiene preparados conjuntos para que no sea necesario ir haciendo particiones. \n",
        "Para este caso el conjunto de entrenamiento será el train2014 y el de test val2014. YOLO necesita un archivo .txt donde tenga anotadas las imágenes que va a usar en el entrenamiento y lo mismo en el caso de las de test, estos archivos son 5k.txt para las imágenes de test y trainvalno5k.txt para las de entrenamiento.\n",
        "\n",
        "<img src=\"imágenes/cocoDataset.png\" style=\"width:500px;\">\n",
        "\n",
        "En este notebook se han usado 117.264 imágenes de entrenamiento y 4996 de test."
      ]
    },
    {
      "metadata": {
        "id": "yuMoAJN_5ZXF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 5- Entrenamiento\n",
        "\n",
        "El primer paso antes de empezar a entrenar será cambiar el archivo de configuración cfg/coco.data para que apunte a las imágenes que hemos descargado. \n",
        "\n",
        "<img src=\"imágenes/cocodata.png\" style=\"width:500px;\">\n",
        "\n",
        "A parte de este fichero también es necesario que modifiquemos el fichero cfg/yolov3.cfg, indicando que vamos a realizar el entrenamiento:\n",
        "\n",
        "<img src=\"imágenes/yolov3cfg.png\" style=\"width:250px;\">\n",
        "\n",
        "Hay dos maneras de entrenar la red YOLO: o bien usando unos pesos pre-entrenados o partiendo de cero. En este caso se van a usar unos pesos previamente pre-entrenados llamados *darknet53.conv.74*, estos pesos que usamos provienen del modelo darknet53. Y comenzamos el entrenamiento."
      ]
    },
    {
      "metadata": {
        "id": "pKQJXi525ZXF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "./darknet detector train cfg/coco.data cfg/yolov3.cfg darknet53.conv.74"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qPOHnbl-5ZXH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 6- Evaluación\n",
        "Una vez finalizado el entrenamiento, y antes de comprobar que nos funciona en imágenes reales, vamos a evaluar el modelo construido en el conjunto de test. Como entrenar un modelo para CoCO lleva mucho tiempo vamos a coger los pesos ya entrenados que son proporcionados en la página de YOLO. Para poder ejecutar este test es necesario descargarse una librería [darknet](https://github.com/AlexeyAB/darknet) desde otro sitio que tiene un script que permite ejecutar la siguiente instrucción. Además también hará falta configurar el archivo voc.data, donde indiquemos las rutas de las listas de imágenes. Una vez realizado este paso, ejecutamos la siguiente instrucción.\n"
      ]
    },
    {
      "metadata": {
        "id": "9D4t5GOJ5ZXH",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        " ./darknet detector map cfg/coco.data cfg/yolov3.cfg yolov3.weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KJNcbuYg5ZXJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Al acabar, el comando anterior nos mostrará el valor de AP para cada clase del dataset, y el valor global de map, lo que nos permite clasificarlo como aceptable o no.\n",
        "\n",
        "<img src=\"imágenes/map2.png\" style=\"width:500px;\">"
      ]
    },
    {
      "metadata": {
        "id": "hB-Z-J9s5ZXJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 7- Predicción\n",
        "Por último probamos nuestro modelo con imágenes que no se encontraban en el conjunto inicial. Ejecutamos para ello la siguiente instrucción con una imagen."
      ]
    },
    {
      "metadata": {
        "id": "D_RZKD3w5ZXK",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "./darknet detect cfg/yolov3.cfg yolov3.weights data/dog.jpg "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t3oUe3Uh5ZXL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Por último probamos nuestro modelo con imágenes que no se encontraran en el conjunto inicial. Ejecutamos para ello la siguiente instrucción con una imagen.\n",
        "\n",
        "<img src=\"imágenes/predicCoco.png\" style=\"width:500px;\">\n",
        "\n",
        "Y en la imagen resultado lo vemos:\n",
        "\n",
        "<img src=\"imágenes/finalCoco.png\" style=\"width:500px;\">"
      ]
    },
    {
      "metadata": {
        "id": "nfkAj_PN5ZXM",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}